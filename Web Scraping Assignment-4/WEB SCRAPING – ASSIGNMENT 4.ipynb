{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31c8621f",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">WEB SCRAPING – ASSIGNMENT 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83531c6",
   "metadata": {},
   "source": [
    "# • Read all the problem statements, notes carefully and scrape the required data using any web scraping tool of your choice.\n",
    "• You have to handle commonly occurring EXCEPTIONS by using exception handling programing. To get information about selenium Exceptions. You may visit following links:\n",
    "1. https://selenium-python.readthedocs.io/api.html\n",
    "2. https://www.guru99.com/exception-handling-selenium.html\n",
    "3. https://stackoverflow.com/questions/38022658/selenium-python-handling-no-such-element- exception/38023345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "833e110f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in c:\\users\\nirma\\anaconda3\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\nirma\\anaconda3\\lib\\site-packages (from bs4) (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\nirma\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (2.3.1)\n",
      "Requirement already satisfied: requests in c:\\users\\nirma\\anaconda3\\lib\\site-packages (2.27.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nirma\\anaconda3\\lib\\site-packages (from requests) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\nirma\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nirma\\anaconda3\\lib\\site-packages (from requests) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\nirma\\anaconda3\\lib\\site-packages (from requests) (1.26.9)\n",
      "Requirement already satisfied: html5lib in c:\\users\\nirma\\anaconda3\\lib\\site-packages (1.1)\n",
      "Requirement already satisfied: webencodings in c:\\users\\nirma\\anaconda3\\lib\\site-packages (from html5lib) (0.5.1)\n",
      "Requirement already satisfied: six>=1.9 in c:\\users\\nirma\\anaconda3\\lib\\site-packages (from html5lib) (1.16.0)\n",
      "Requirement already satisfied: selenium in c:\\users\\nirma\\anaconda3\\lib\\site-packages (4.7.2)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in c:\\users\\nirma\\anaconda3\\lib\\site-packages (from selenium) (1.26.9)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\nirma\\anaconda3\\lib\\site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\nirma\\anaconda3\\lib\\site-packages (from selenium) (2021.10.8)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\nirma\\anaconda3\\lib\\site-packages (from selenium) (0.22.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\nirma\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.1.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\nirma\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\nirma\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: sniffio in c:\\users\\nirma\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\nirma\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: outcome in c:\\users\\nirma\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\nirma\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.0)\n",
      "Requirement already satisfied: idna in c:\\users\\nirma\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: pycparser in c:\\users\\nirma\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\nirma\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\nirma\\anaconda3\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\nirma\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "# necessary packages\n",
    "!pip install bs4\n",
    "!pip install requests\n",
    "!pip install html5lib\n",
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "4e1cafce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "import selenium \n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import StaleElementReferenceException,NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067f0183",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">1. Scrape the details of most viewed videos on YouTube from Wikipedia.Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\n",
    "You need to find following details:                   \n",
    "A) Rank                            \n",
    "B) Name               \n",
    "C) Artist           \n",
    "D) Upload date                 \n",
    "E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6132a155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Chrome WebDriver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\nirma\\Downloads\\chromedriver-win64\\chromedriver-win64\\chromedriver.exe\")\n",
    "driver.get(\"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\")\n",
    "driver.maximize_window()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab9850bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the rank\n",
    "rank =[]\n",
    "try:\n",
    "    Ranks=driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[1]')\n",
    "    for i in Ranks:\n",
    "        rank.append(i.text)\n",
    "except NoSuchElementException: #handling no such element exception\n",
    "    rank.append('No details available')\n",
    "except StaleElementReferenceException: #handling Stale element exception\n",
    "    rank.append('No details available')\n",
    "time.sleep(2)\n",
    "\n",
    "#scraping the names\n",
    "name =[]\n",
    "try:\n",
    "    names=driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[2]')\n",
    "    for i in names:\n",
    "        name.append(i.text)\n",
    "except NoSuchElementException: #handling no such element exception\n",
    "    name.append('No details available')\n",
    "except StaleElementReferenceException: #handling Stale element exception\n",
    "    name.append('No details available')\n",
    "time.sleep(2) \n",
    "\n",
    "#scraping the artist\n",
    "artist =[]\n",
    "try:\n",
    "    art=driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[3]')\n",
    "    for i in art:\n",
    "        artist.append(i.text)\n",
    "except NoSuchElementException: #handling no such element exception\n",
    "    artist.append('No details available')\n",
    "except StaleElementReferenceException: #handling Stale element exception\n",
    "    artist.append('No details available')\n",
    "time.sleep(2) \n",
    "\n",
    "#scraping the Upload date\n",
    "Upload_date =[]\n",
    "try:\n",
    "    date=driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[4]\")\n",
    "    for i in date:\n",
    "        Upload_date.append(i.text)\n",
    "except NoSuchElementException: #handling no such element exception\n",
    "    Upload_date.append('No details available')\n",
    "except StaleElementReferenceException: #handling Stale element exception\n",
    "    Upload_date.append('No details available')\n",
    "time.sleep(2)  \n",
    "\n",
    "#scraping the views\n",
    "views =[]\n",
    "try:\n",
    "    view=driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[5]\")\n",
    "    for i in view:\n",
    "        views.append(i.text)\n",
    "except NoSuchElementException: #handling no such element exception\n",
    "    views.append('No details available')\n",
    "except StaleElementReferenceException: #handling Stale element exception\n",
    "    views.append('No details available')\n",
    "time.sleep(2)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc99acf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 30 30 30 30\n"
     ]
    }
   ],
   "source": [
    "# print the length of different attributes\n",
    "print(len(rank),len(name),len(artist),len(Upload_date),len(views))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3dca58e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RANK</th>\n",
       "      <th>NAME</th>\n",
       "      <th>ARTIST</th>\n",
       "      <th>UPLOAD DATE</th>\n",
       "      <th>VIEWS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>\"Baby Shark Dance\"[6]</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>13.48</td>\n",
       "      <td>June 17, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>\"Despacito\"[9]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>8.28</td>\n",
       "      <td>January 12, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[17]</td>\n",
       "      <td>LooLoo Kids - Nursery Rhymes and Children's Songs</td>\n",
       "      <td>6.82</td>\n",
       "      <td>October 8, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>\"Bath Song\"[18]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>6.45</td>\n",
       "      <td>May 2, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>\"Shape of You\"[19]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>6.11</td>\n",
       "      <td>January 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>\"See You Again\"[22]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>6.05</td>\n",
       "      <td>April 6, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>\"Wheels on the Bus\"[27]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>5.62</td>\n",
       "      <td>May 24, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>\"Phonics Song with Two Words\"[28]</td>\n",
       "      <td>ChuChu TV Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>5.52</td>\n",
       "      <td>March 6, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>\"Uptown Funk\"[29]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>5.05</td>\n",
       "      <td>November 19, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[30]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>4.99</td>\n",
       "      <td>February 27, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>\"Gangnam Style\"[31]</td>\n",
       "      <td>officialpsy</td>\n",
       "      <td>4.92</td>\n",
       "      <td>July 15, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[36]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>4.56</td>\n",
       "      <td>January 31, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>\"Dame Tu Cosita\"[37]</td>\n",
       "      <td>Ultra Records</td>\n",
       "      <td>4.46</td>\n",
       "      <td>April 5, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>\"Axel F\"[38]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>4.09</td>\n",
       "      <td>June 16, 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>\"Sugar\"[39]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.95</td>\n",
       "      <td>January 14, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>\"Counting Stars\"[40]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>3.89</td>\n",
       "      <td>May 31, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>\"Roar\"[41]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.89</td>\n",
       "      <td>September 5, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Baa Baa Black Sheep\"[42]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>3.80</td>\n",
       "      <td>June 25, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[43]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>3.75</td>\n",
       "      <td>June 4, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>\"Sorry\"[44]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>3.72</td>\n",
       "      <td>October 22, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>\"Lakdi Ki Kathi\"[45]</td>\n",
       "      <td>Jingle Toons</td>\n",
       "      <td>3.71</td>\n",
       "      <td>June 14, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>\"Thinking Out Loud\"[46]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.67</td>\n",
       "      <td>October 7, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>\"Dark Horse\"[47]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.60</td>\n",
       "      <td>February 20, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>\"Humpty the train on a fruits ride\"[48]</td>\n",
       "      <td>Kiddiestv Hindi - Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>3.58</td>\n",
       "      <td>January 26, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>\"Perfect\"[49]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.56</td>\n",
       "      <td>November 9, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>\"Let Her Go\"[50]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>3.53</td>\n",
       "      <td>July 25, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>\"Faded\"[51]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>3.53</td>\n",
       "      <td>December 3, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>\"Girls Like You\"[52]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.50</td>\n",
       "      <td>May 31, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>\"Shree Hanuman Chalisa\"[53]</td>\n",
       "      <td>T-Series Bhakti Sagar</td>\n",
       "      <td>3.48</td>\n",
       "      <td>May 10, 2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>\"Lean On\"[54]</td>\n",
       "      <td>Major Lazer Official</td>\n",
       "      <td>3.48</td>\n",
       "      <td>March 22, 2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RANK                                             NAME  \\\n",
       "0    1.                            \"Baby Shark Dance\"[6]   \n",
       "1    2.                                   \"Despacito\"[9]   \n",
       "2    3.                       \"Johny Johny Yes Papa\"[17]   \n",
       "3    4.                                  \"Bath Song\"[18]   \n",
       "4    5.                               \"Shape of You\"[19]   \n",
       "5    6.                              \"See You Again\"[22]   \n",
       "6    7.                          \"Wheels on the Bus\"[27]   \n",
       "7    8.                \"Phonics Song with Two Words\"[28]   \n",
       "8    9.                                \"Uptown Funk\"[29]   \n",
       "9   10.  \"Learning Colors – Colorful Eggs on a Farm\"[30]   \n",
       "10  11.                              \"Gangnam Style\"[31]   \n",
       "11  12.   \"Masha and the Bear – Recipe for Disaster\"[36]   \n",
       "12  13.                             \"Dame Tu Cosita\"[37]   \n",
       "13  14.                                     \"Axel F\"[38]   \n",
       "14  15.                                      \"Sugar\"[39]   \n",
       "15  16.                             \"Counting Stars\"[40]   \n",
       "16  17.                                       \"Roar\"[41]   \n",
       "17  18.                        \"Baa Baa Black Sheep\"[42]   \n",
       "18  19.           \"Waka Waka (This Time for Africa)\"[43]   \n",
       "19  20.                                      \"Sorry\"[44]   \n",
       "20  21.                             \"Lakdi Ki Kathi\"[45]   \n",
       "21  22.                          \"Thinking Out Loud\"[46]   \n",
       "22  23.                                 \"Dark Horse\"[47]   \n",
       "23  24.          \"Humpty the train on a fruits ride\"[48]   \n",
       "24  25.                                    \"Perfect\"[49]   \n",
       "25  26.                                 \"Let Her Go\"[50]   \n",
       "26  27.                                      \"Faded\"[51]   \n",
       "27  28.                             \"Girls Like You\"[52]   \n",
       "28  29.                      \"Shree Hanuman Chalisa\"[53]   \n",
       "29  30.                                    \"Lean On\"[54]   \n",
       "\n",
       "                                               ARTIST UPLOAD DATE  \\\n",
       "0         Pinkfong Baby Shark - Kids' Songs & Stories       13.48   \n",
       "1                                          Luis Fonsi        8.28   \n",
       "2   LooLoo Kids - Nursery Rhymes and Children's Songs        6.82   \n",
       "3                          Cocomelon - Nursery Rhymes        6.45   \n",
       "4                                          Ed Sheeran        6.11   \n",
       "5                                         Wiz Khalifa        6.05   \n",
       "6                          Cocomelon - Nursery Rhymes        5.62   \n",
       "7               ChuChu TV Nursery Rhymes & Kids Songs        5.52   \n",
       "8                                         Mark Ronson        5.05   \n",
       "9                                         Miroshka TV        4.99   \n",
       "10                                        officialpsy        4.92   \n",
       "11                                         Get Movies        4.56   \n",
       "12                                      Ultra Records        4.46   \n",
       "13                                         Crazy Frog        4.09   \n",
       "14                                           Maroon 5        3.95   \n",
       "15                                        OneRepublic        3.89   \n",
       "16                                         Katy Perry        3.89   \n",
       "17                         Cocomelon - Nursery Rhymes        3.80   \n",
       "18                                            Shakira        3.75   \n",
       "19                                      Justin Bieber        3.72   \n",
       "20                                       Jingle Toons        3.71   \n",
       "21                                         Ed Sheeran        3.67   \n",
       "22                                         Katy Perry        3.60   \n",
       "23      Kiddiestv Hindi - Nursery Rhymes & Kids Songs        3.58   \n",
       "24                                         Ed Sheeran        3.56   \n",
       "25                                          Passenger        3.53   \n",
       "26                                        Alan Walker        3.53   \n",
       "27                                           Maroon 5        3.50   \n",
       "28                              T-Series Bhakti Sagar        3.48   \n",
       "29                               Major Lazer Official        3.48   \n",
       "\n",
       "                VIEWS  \n",
       "0       June 17, 2016  \n",
       "1    January 12, 2017  \n",
       "2     October 8, 2016  \n",
       "3         May 2, 2018  \n",
       "4    January 30, 2017  \n",
       "5       April 6, 2015  \n",
       "6        May 24, 2018  \n",
       "7       March 6, 2014  \n",
       "8   November 19, 2014  \n",
       "9   February 27, 2018  \n",
       "10      July 15, 2012  \n",
       "11   January 31, 2012  \n",
       "12      April 5, 2018  \n",
       "13      June 16, 2009  \n",
       "14   January 14, 2015  \n",
       "15       May 31, 2013  \n",
       "16  September 5, 2013  \n",
       "17      June 25, 2018  \n",
       "18       June 4, 2010  \n",
       "19   October 22, 2015  \n",
       "20      June 14, 2018  \n",
       "21    October 7, 2014  \n",
       "22  February 20, 2014  \n",
       "23   January 26, 2018  \n",
       "24   November 9, 2017  \n",
       "25      July 25, 2012  \n",
       "26   December 3, 2015  \n",
       "27       May 31, 2018  \n",
       "28       May 10, 2011  \n",
       "29     March 22, 2015  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe for different attributes\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'RANK':rank,'NAME':name,'ARTIST':artist,'UPLOAD DATE':Upload_date,\"VIEWS\":views})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0046cfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2489f3",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">2. Scrape the details team India’s international fixtures from bcci.tv.Url = https://www.bcci.tv/.    \n",
    "You need to find following details:                       \n",
    "A) Series                 \n",
    "B) Place                 \n",
    "C) Date                  \n",
    "D) Time                                                  \n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ce203384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Chrome WebDriver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\nirma\\Downloads\\chromedriver-win64\\chromedriver-win64\\chromedriver.exe\")\n",
    "driver.get(\"https://www.bcci.tv/\")\n",
    "driver.maximize_window()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a5f52046",
   "metadata": {},
   "outputs": [],
   "source": [
    "#close the pop-up\n",
    "close_popup= driver.find_element(By.XPATH,'//button[@class=\"close-button page-close\"]')    \n",
    "close_popup.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eda684ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click on internation fixture\n",
    "international = driver.find_element(By.XPATH,'/html/body/header/div[3]/div[1]/ul/div[1]/a[2]')\n",
    "international.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "987843c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping series name\n",
    "series=[]\n",
    "ser=driver.find_elements(By.XPATH,'//h5[@class=\"match-tournament-name ng-binding\"]')\n",
    "try:\n",
    "    for i in ser:\n",
    "        series.append(i.text)\n",
    "\n",
    "except NoSuchElementException: #handling no such element exception\n",
    "    series.append('No details available')\n",
    "except StaleElementReferenceException: #handling Stale element exception\n",
    "     series.append('No details available')\n",
    "time.sleep(2) \n",
    "\n",
    "\n",
    "#scraping place name \n",
    "place=[]\n",
    "pla=driver.find_elements(By.XPATH,'//div[@class=\"match-place ng-scope\"]')\n",
    "try:\n",
    "    for i in pla:\n",
    "        place.append(i.text)\n",
    "\n",
    "except NoSuchElementException: #handling no such element exception\n",
    "    place.append('No details available')\n",
    "except StaleElementReferenceException: #handling Stale element exception\n",
    "     place.append('No details available')\n",
    "time.sleep(2) \n",
    "\n",
    "#scraping date\n",
    "Date=[]\n",
    "din=driver.find_elements(By.XPATH,'//div[@class=\"match-dates ng-binding\"]')\n",
    "try:\n",
    "    for i in din:\n",
    "        Date.append(i.text)\n",
    "\n",
    "except NoSuchElementException: #handling no such element exception\n",
    "    Date.append('No details available')\n",
    "except StaleElementReferenceException: #handling Stale element exception\n",
    "     Date.append('No details available')\n",
    "time.sleep(2) \n",
    "\n",
    "#scraping match time\n",
    "\n",
    "clock=[]\n",
    "samay=driver.find_elements(By.XPATH,'//div[@class=\"match-time no-margin ng-binding\"]')\n",
    "try:\n",
    "    for i in samay:\n",
    "        clock.append(i.text)\n",
    "\n",
    "except NoSuchElementException: #handling no such element exception\n",
    "    clock.append('No details available')\n",
    "except StaleElementReferenceException: #handling Stale element exception\n",
    "     clock.append('No details available')\n",
    "time.sleep(2) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b47483d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SERIES NAME</th>\n",
       "      <th>PLACE</th>\n",
       "      <th>DATE</th>\n",
       "      <th>TIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>QUADRANGULAR MENS U19 ONE DAY SERIES</td>\n",
       "      <td>DVR Ground,Mulapadu, Vijayawada</td>\n",
       "      <td>13 NOVEMBER, 2023</td>\n",
       "      <td>9:00 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>QUADRANGULAR MENS U19 ONE DAY SERIES</td>\n",
       "      <td>CP Ground,Mulapadu, Vijayawada</td>\n",
       "      <td>13 NOVEMBER, 2023</td>\n",
       "      <td>9:00 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>QUADRANGULAR MENS U19 ONE DAY SERIES</td>\n",
       "      <td>DVR Ground,Mulapadu, Vijayawada</td>\n",
       "      <td>15 NOVEMBER, 2023</td>\n",
       "      <td>9:00 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>QUADRANGULAR MENS U19 ONE DAY SERIES</td>\n",
       "      <td>CP Ground,Mulapadu, Vijayawada</td>\n",
       "      <td>15 NOVEMBER, 2023</td>\n",
       "      <td>9:00 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>QUADRANGULAR MENS U19 ONE DAY SERIES</td>\n",
       "      <td>DVR Ground,Mulapadu, Vijayawada</td>\n",
       "      <td>17 NOVEMBER, 2023</td>\n",
       "      <td>9:00 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>QUADRANGULAR MENS U19 ONE DAY SERIES</td>\n",
       "      <td>CP Ground,Mulapadu, Vijayawada</td>\n",
       "      <td>17 NOVEMBER, 2023</td>\n",
       "      <td>9:00 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>QUADRANGULAR MENS U19 ONE DAY SERIES</td>\n",
       "      <td>DVR Ground,Mulapadu, Vijayawada</td>\n",
       "      <td>20 NOVEMBER, 2023</td>\n",
       "      <td>9:00 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>QUADRANGULAR MENS U19 ONE DAY SERIES</td>\n",
       "      <td>CP Ground,Mulapadu, Vijayawada</td>\n",
       "      <td>20 NOVEMBER, 2023</td>\n",
       "      <td>9:00 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>QUADRANGULAR MENS U19 ONE DAY SERIES</td>\n",
       "      <td>DVR Ground,Mulapadu, Vijayawada</td>\n",
       "      <td>22 NOVEMBER, 2023</td>\n",
       "      <td>9:00 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>QUADRANGULAR MENS U19 ONE DAY SERIES</td>\n",
       "      <td>CP Ground,Mulapadu, Vijayawada</td>\n",
       "      <td>22 NOVEMBER, 2023</td>\n",
       "      <td>9:00 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>QUADRANGULAR MENS U19 ONE DAY SERIES</td>\n",
       "      <td>DVR Ground,Mulapadu, Vijayawada</td>\n",
       "      <td>24 NOVEMBER, 2023</td>\n",
       "      <td>9:00 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>QUADRANGULAR MENS U19 ONE DAY SERIES</td>\n",
       "      <td>CP Ground,Mulapadu, Vijayawada</td>\n",
       "      <td>24 NOVEMBER, 2023</td>\n",
       "      <td>9:00 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>QUADRANGULAR MENS U19 ONE DAY SERIES</td>\n",
       "      <td>CP Ground,Mulapadu, Vijayawada</td>\n",
       "      <td>27 NOVEMBER, 2023</td>\n",
       "      <td>9:00 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>QUADRANGULAR MENS U19 ONE DAY SERIES</td>\n",
       "      <td>DVR Ground,Mulapadu, Vijayawada</td>\n",
       "      <td>27 NOVEMBER, 2023</td>\n",
       "      <td>9:00 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>AUSTRALIA TOUR OF INDIA 2023-24</td>\n",
       "      <td>Dr YS Rajasekhara Reddy ACA-VDCA Cricket Stadi...</td>\n",
       "      <td>23 NOVEMBER, 2023</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>AUSTRALIA TOUR OF INDIA 2023-24</td>\n",
       "      <td>Greenfield International Stadium, Thiruvananth...</td>\n",
       "      <td>26 NOVEMBER, 2023</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>AUSTRALIA TOUR OF INDIA 2023-24</td>\n",
       "      <td>Barsapara Cricket Stadium, Guwahati</td>\n",
       "      <td>28 NOVEMBER, 2023</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>AUSTRALIA TOUR OF INDIA 2023-24</td>\n",
       "      <td>Vidarbha Cricket Association Stadium, Nagpur</td>\n",
       "      <td>1 DECEMBER, 2023</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>AUSTRALIA TOUR OF INDIA 2023-24</td>\n",
       "      <td>Rajiv Gandhi International Stadium, Hyderabad</td>\n",
       "      <td>3 DECEMBER, 2023</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>INDIA TOUR OF SOUTH AFRICA 2023-24</td>\n",
       "      <td>Kingsmead, Durban</td>\n",
       "      <td>10 DECEMBER, 2023</td>\n",
       "      <td>9:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>INDIA TOUR OF SOUTH AFRICA 2023-24</td>\n",
       "      <td>St George's Park, Gqeberha</td>\n",
       "      <td>12 DECEMBER, 2023</td>\n",
       "      <td>9:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>INDIA TOUR OF SOUTH AFRICA 2023-24</td>\n",
       "      <td>The Wanderers Stadium, Johannesburg</td>\n",
       "      <td>14 DECEMBER, 2023</td>\n",
       "      <td>9:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>INDIA TOUR OF SOUTH AFRICA 2023-24</td>\n",
       "      <td>Johannesburg</td>\n",
       "      <td>17 DECEMBER, 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>INDIA TOUR OF SOUTH AFRICA 2023-24</td>\n",
       "      <td>St George's Park, Gqeberha</td>\n",
       "      <td>19 DECEMBER, 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>INDIA TOUR OF SOUTH AFRICA 2023-24</td>\n",
       "      <td>Boland Park, Paarl</td>\n",
       "      <td>21 DECEMBER, 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>INDIA TOUR OF SOUTH AFRICA 2023-24</td>\n",
       "      <td>SuperSport Park, Centurion</td>\n",
       "      <td>26 DECEMBER, 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>INDIA TOUR OF SOUTH AFRICA 2023-24</td>\n",
       "      <td>Newlands, Cape Town</td>\n",
       "      <td>3 JANUARY, 2024</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>AFGHANISTAN TOUR OF INDIA 2023-24</td>\n",
       "      <td>Punjab Cricket Association IS Bindra Stadium, ...</td>\n",
       "      <td>11 JANUARY, 2024</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>AFGHANISTAN TOUR OF INDIA 2023-24</td>\n",
       "      <td>Holkar Cricket Stadium, Indore</td>\n",
       "      <td>14 JANUARY, 2024</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>AFGHANISTAN TOUR OF INDIA 2023-24</td>\n",
       "      <td>M Chinnaswamy Stadium, Bengaluru</td>\n",
       "      <td>17 JANUARY, 2024</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ENGLAND TOUR OF INDIA 2023-24</td>\n",
       "      <td>Rajiv Gandhi International Stadium, Hyderabad</td>\n",
       "      <td>25 JANUARY, 2024</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ENGLAND TOUR OF INDIA 2023-24</td>\n",
       "      <td>Dr YS Rajasekhara Reddy ACA-VDCA Cricket Stadi...</td>\n",
       "      <td>2 FEBRUARY, 2024</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ENGLAND TOUR OF INDIA 2023-24</td>\n",
       "      <td>Saurashtra Cricket Association Stadium, Rajkot</td>\n",
       "      <td>15 FEBRUARY, 2024</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>ENGLAND TOUR OF INDIA 2023-24</td>\n",
       "      <td>JSCA International Stadium Complex, Ranchi</td>\n",
       "      <td>23 FEBRUARY, 2024</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>ENGLAND TOUR OF INDIA 2023-24</td>\n",
       "      <td>Himachal Pradesh Cricket Association Stadium, ...</td>\n",
       "      <td>7 MARCH, 2024</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             SERIES NAME  \\\n",
       "0   QUADRANGULAR MENS U19 ONE DAY SERIES   \n",
       "1   QUADRANGULAR MENS U19 ONE DAY SERIES   \n",
       "2   QUADRANGULAR MENS U19 ONE DAY SERIES   \n",
       "3   QUADRANGULAR MENS U19 ONE DAY SERIES   \n",
       "4   QUADRANGULAR MENS U19 ONE DAY SERIES   \n",
       "5   QUADRANGULAR MENS U19 ONE DAY SERIES   \n",
       "6   QUADRANGULAR MENS U19 ONE DAY SERIES   \n",
       "7   QUADRANGULAR MENS U19 ONE DAY SERIES   \n",
       "8   QUADRANGULAR MENS U19 ONE DAY SERIES   \n",
       "9   QUADRANGULAR MENS U19 ONE DAY SERIES   \n",
       "10  QUADRANGULAR MENS U19 ONE DAY SERIES   \n",
       "11  QUADRANGULAR MENS U19 ONE DAY SERIES   \n",
       "12  QUADRANGULAR MENS U19 ONE DAY SERIES   \n",
       "13  QUADRANGULAR MENS U19 ONE DAY SERIES   \n",
       "14       AUSTRALIA TOUR OF INDIA 2023-24   \n",
       "15       AUSTRALIA TOUR OF INDIA 2023-24   \n",
       "16       AUSTRALIA TOUR OF INDIA 2023-24   \n",
       "17       AUSTRALIA TOUR OF INDIA 2023-24   \n",
       "18       AUSTRALIA TOUR OF INDIA 2023-24   \n",
       "19    INDIA TOUR OF SOUTH AFRICA 2023-24   \n",
       "20    INDIA TOUR OF SOUTH AFRICA 2023-24   \n",
       "21    INDIA TOUR OF SOUTH AFRICA 2023-24   \n",
       "22    INDIA TOUR OF SOUTH AFRICA 2023-24   \n",
       "23    INDIA TOUR OF SOUTH AFRICA 2023-24   \n",
       "24    INDIA TOUR OF SOUTH AFRICA 2023-24   \n",
       "25    INDIA TOUR OF SOUTH AFRICA 2023-24   \n",
       "26    INDIA TOUR OF SOUTH AFRICA 2023-24   \n",
       "27     AFGHANISTAN TOUR OF INDIA 2023-24   \n",
       "28     AFGHANISTAN TOUR OF INDIA 2023-24   \n",
       "29     AFGHANISTAN TOUR OF INDIA 2023-24   \n",
       "30         ENGLAND TOUR OF INDIA 2023-24   \n",
       "31         ENGLAND TOUR OF INDIA 2023-24   \n",
       "32         ENGLAND TOUR OF INDIA 2023-24   \n",
       "33         ENGLAND TOUR OF INDIA 2023-24   \n",
       "34         ENGLAND TOUR OF INDIA 2023-24   \n",
       "\n",
       "                                                PLACE               DATE  \\\n",
       "0                     DVR Ground,Mulapadu, Vijayawada  13 NOVEMBER, 2023   \n",
       "1                      CP Ground,Mulapadu, Vijayawada  13 NOVEMBER, 2023   \n",
       "2                     DVR Ground,Mulapadu, Vijayawada  15 NOVEMBER, 2023   \n",
       "3                      CP Ground,Mulapadu, Vijayawada  15 NOVEMBER, 2023   \n",
       "4                     DVR Ground,Mulapadu, Vijayawada  17 NOVEMBER, 2023   \n",
       "5                      CP Ground,Mulapadu, Vijayawada  17 NOVEMBER, 2023   \n",
       "6                     DVR Ground,Mulapadu, Vijayawada  20 NOVEMBER, 2023   \n",
       "7                      CP Ground,Mulapadu, Vijayawada  20 NOVEMBER, 2023   \n",
       "8                     DVR Ground,Mulapadu, Vijayawada  22 NOVEMBER, 2023   \n",
       "9                      CP Ground,Mulapadu, Vijayawada  22 NOVEMBER, 2023   \n",
       "10                    DVR Ground,Mulapadu, Vijayawada  24 NOVEMBER, 2023   \n",
       "11                     CP Ground,Mulapadu, Vijayawada  24 NOVEMBER, 2023   \n",
       "12                     CP Ground,Mulapadu, Vijayawada  27 NOVEMBER, 2023   \n",
       "13                    DVR Ground,Mulapadu, Vijayawada  27 NOVEMBER, 2023   \n",
       "14  Dr YS Rajasekhara Reddy ACA-VDCA Cricket Stadi...  23 NOVEMBER, 2023   \n",
       "15  Greenfield International Stadium, Thiruvananth...  26 NOVEMBER, 2023   \n",
       "16                Barsapara Cricket Stadium, Guwahati  28 NOVEMBER, 2023   \n",
       "17       Vidarbha Cricket Association Stadium, Nagpur   1 DECEMBER, 2023   \n",
       "18      Rajiv Gandhi International Stadium, Hyderabad   3 DECEMBER, 2023   \n",
       "19                                  Kingsmead, Durban  10 DECEMBER, 2023   \n",
       "20                         St George's Park, Gqeberha  12 DECEMBER, 2023   \n",
       "21                The Wanderers Stadium, Johannesburg  14 DECEMBER, 2023   \n",
       "22                                       Johannesburg  17 DECEMBER, 2023   \n",
       "23                         St George's Park, Gqeberha  19 DECEMBER, 2023   \n",
       "24                                 Boland Park, Paarl  21 DECEMBER, 2023   \n",
       "25                         SuperSport Park, Centurion  26 DECEMBER, 2023   \n",
       "26                                Newlands, Cape Town    3 JANUARY, 2024   \n",
       "27  Punjab Cricket Association IS Bindra Stadium, ...   11 JANUARY, 2024   \n",
       "28                     Holkar Cricket Stadium, Indore   14 JANUARY, 2024   \n",
       "29                   M Chinnaswamy Stadium, Bengaluru   17 JANUARY, 2024   \n",
       "30      Rajiv Gandhi International Stadium, Hyderabad   25 JANUARY, 2024   \n",
       "31  Dr YS Rajasekhara Reddy ACA-VDCA Cricket Stadi...   2 FEBRUARY, 2024   \n",
       "32     Saurashtra Cricket Association Stadium, Rajkot  15 FEBRUARY, 2024   \n",
       "33         JSCA International Stadium Complex, Ranchi  23 FEBRUARY, 2024   \n",
       "34  Himachal Pradesh Cricket Association Stadium, ...      7 MARCH, 2024   \n",
       "\n",
       "           TIME  \n",
       "0   9:00 AM IST  \n",
       "1   9:00 AM IST  \n",
       "2   9:00 AM IST  \n",
       "3   9:00 AM IST  \n",
       "4   9:00 AM IST  \n",
       "5   9:00 AM IST  \n",
       "6   9:00 AM IST  \n",
       "7   9:00 AM IST  \n",
       "8   9:00 AM IST  \n",
       "9   9:00 AM IST  \n",
       "10  9:00 AM IST  \n",
       "11  9:00 AM IST  \n",
       "12  9:00 AM IST  \n",
       "13  9:00 AM IST  \n",
       "14  7:00 PM IST  \n",
       "15  7:00 PM IST  \n",
       "16  7:00 PM IST  \n",
       "17  7:00 PM IST  \n",
       "18  7:00 PM IST  \n",
       "19  9:30 PM IST  \n",
       "20  9:30 PM IST  \n",
       "21  9:30 PM IST  \n",
       "22  2:00 PM IST  \n",
       "23  2:00 PM IST  \n",
       "24  2:00 PM IST  \n",
       "25  1:30 PM IST  \n",
       "26  1:30 PM IST  \n",
       "27  7:00 PM IST  \n",
       "28  7:00 PM IST  \n",
       "29  7:00 PM IST  \n",
       "30  9:30 AM IST  \n",
       "31  9:30 AM IST  \n",
       "32  9:30 AM IST  \n",
       "33  9:30 AM IST  \n",
       "34  9:30 AM IST  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe for different attributes\n",
    "import pandas as pd\n",
    "international_fixtures= pd.DataFrame({'SERIES NAME':series,'PLACE':place ,'DATE':Date,\"TIME\":clock})\n",
    "international_fixtures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc51dab3",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">3. Scrape the details of State-wise GDP of India from statisticstime.com.Url = http://statisticstimes.com/        \n",
    "You have to find following details:                                         \n",
    "A) Rank                  \n",
    "B) State                      \n",
    "C) GSDP(18-19)- at current prices                     \n",
    "D) GSDP(19-20)- at current prices               \n",
    "E) Share(18-19)                    \n",
    "F) GDP($ billion)                                             \n",
    "Note: - From statisticstimes home page you have to reach to economy page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5d15d888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Chrome WebDriver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\nirma\\Downloads\\chromedriver-win64\\chromedriver-win64\\chromedriver.exe\")\n",
    "driver.get(\"http://statisticstimes.com/\")\n",
    "driver.maximize_window()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8431824f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click on \"economy\" button \n",
    "economy = driver.find_element(By.XPATH,\"//*[@id='top']/div[2]/div[2]/button\")\n",
    "economy.click()\n",
    "time.sleep(5)\n",
    "\n",
    "#click on \"india\" button \n",
    "india = driver.find_element(By.XPATH,\"//*[@id='top']/div[2]/div[2]/div/a[3]\")\n",
    "india.click()\n",
    "time.sleep(5)\n",
    "#click on \"GDP of indian states\" button\n",
    "gdp = driver.find_element(By.XPATH,\"/html/body/div[2]/div[2]/div[2]/ul/li[1]/a\")\n",
    "gdp.click()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "767081d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the rank\n",
    "rank =[]\n",
    "try:\n",
    "    Ranks=driver.find_elements(By.XPATH,\"//td[@class='data1']\")\n",
    "    for i in Ranks[:33]:\n",
    "        rank.append(i.text)\n",
    "except NoSuchElementException: #handling no such element exception\n",
    "    rank.append('No details available')\n",
    "except StaleElementReferenceException: #handling Stale element exception\n",
    "    rank.append('No details available')\n",
    "time.sleep(2) \n",
    "\n",
    "#scraping state names\n",
    "state=[]\n",
    "try:\n",
    "    unit = driver.find_elements(By.XPATH,\"//td[@class='name'] \")\n",
    "    for i in unit[:33]:\n",
    "        state.append(i.text)\n",
    "except NoSuchElementException: \n",
    "    state.append(\"-\")\n",
    "except StaleElementReferenceException:\n",
    "    state.apppend(\"-\")\n",
    "time.sleep(2)\n",
    "\n",
    "#scraping  GSDP(18-19)- at current prices\n",
    "\n",
    "GSDP_18_19 =[]\n",
    "try:\n",
    "    gsdp = driver.find_elements(By.XPATH,\"//td[@class='data sorting_1'] \")\n",
    "    for i in gsdp[:33]:\n",
    "        GSDP_18_19.append(i.text)\n",
    "except NoSuchElementException: \n",
    "    GSDP_18_19.append(\"-\")\n",
    "except StaleElementReferenceException:\n",
    "    GSDP_18_19.apppend(\"-\")\n",
    "time.sleep(2)\n",
    "\n",
    "#scraping  GSDP(19-20)- at current prices\n",
    "\n",
    "GSDP_19_20 =[]\n",
    "try:\n",
    "    DP_19_20 = driver.find_elements(By.XPATH,\"//td[@class='data'][1]  \")\n",
    "    for i in DP_19_20[:33]:\n",
    "        GSDP_19_20.append(i.text)\n",
    "except NoSuchElementException: \n",
    "    GSDP_19_20.append(\"-\")\n",
    "except StaleElementReferenceException:\n",
    "    GSDP_19_20.apppend(\"-\")\n",
    "time.sleep(2)\n",
    "\n",
    "#scraping share(18-19)\n",
    "share_18_19=[]\n",
    "try:\n",
    "    share = driver.find_elements(By.XPATH,\" //td[@class='data'][2]\")\n",
    "    for i in share[:33]:\n",
    "        share_18_19.append(i.text)\n",
    "except NoSuchElementException: \n",
    "    share_18_19.append(\"-\")\n",
    "except StaleElementReferenceException:\n",
    "    share_18_19.apppend(\"-\")\n",
    "time.sleep(2)\n",
    "\n",
    "#scraping GDP($ billion)\n",
    "GDP=[]\n",
    "try:\n",
    "    billion = driver.find_elements(By.XPATH,\" //td[@class='data'][3]\")\n",
    "    for i in billion[:33]:\n",
    "        GDP.append(i.text)\n",
    "except NoSuchElementException: \n",
    "    GDP.append(\"-\")\n",
    "except StaleElementReferenceException:\n",
    "    GDP.apppend(\"-\")\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3f9a128c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RANK</th>\n",
       "      <th>STATE</th>\n",
       "      <th>GSDP(18-19)- at current prices</th>\n",
       "      <th>GSDP(19-20)- at current prices</th>\n",
       "      <th>Share(18-19)</th>\n",
       "      <th>GDP($ billion)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>-</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>-</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>1,253,832</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>165.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>942,586</td>\n",
       "      <td>1,020,989</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>143.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>862,957</td>\n",
       "      <td>972,782</td>\n",
       "      <td>4.57%</td>\n",
       "      <td>131.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>861,031</td>\n",
       "      <td>969,604</td>\n",
       "      <td>4.56%</td>\n",
       "      <td>130.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>809,592</td>\n",
       "      <td>906,672</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>122.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>781,653</td>\n",
       "      <td>-</td>\n",
       "      <td>4.14%</td>\n",
       "      <td>118.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>774,870</td>\n",
       "      <td>856,112</td>\n",
       "      <td>4.10%</td>\n",
       "      <td>117.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>734,163</td>\n",
       "      <td>831,610</td>\n",
       "      <td>3.89%</td>\n",
       "      <td>111.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>530,363</td>\n",
       "      <td>611,804</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>80.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>526,376</td>\n",
       "      <td>574,760</td>\n",
       "      <td>2.79%</td>\n",
       "      <td>79.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>487,805</td>\n",
       "      <td>521,275</td>\n",
       "      <td>2.58%</td>\n",
       "      <td>74.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>315,881</td>\n",
       "      <td>-</td>\n",
       "      <td>1.67%</td>\n",
       "      <td>47.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>304,063</td>\n",
       "      <td>329,180</td>\n",
       "      <td>1.61%</td>\n",
       "      <td>46.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>297,204</td>\n",
       "      <td>328,598</td>\n",
       "      <td>1.57%</td>\n",
       "      <td>45.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>245,895</td>\n",
       "      <td>-</td>\n",
       "      <td>1.30%</td>\n",
       "      <td>37.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>155,956</td>\n",
       "      <td>-</td>\n",
       "      <td>0.83%</td>\n",
       "      <td>23.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>153,845</td>\n",
       "      <td>165,472</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>23.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>73,170</td>\n",
       "      <td>80,449</td>\n",
       "      <td>0.39%</td>\n",
       "      <td>11.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>49,845</td>\n",
       "      <td>55,984</td>\n",
       "      <td>0.26%</td>\n",
       "      <td>7.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>42,114</td>\n",
       "      <td>-</td>\n",
       "      <td>0.22%</td>\n",
       "      <td>6.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>34,433</td>\n",
       "      <td>38,253</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>33,481</td>\n",
       "      <td>36,572</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>28,723</td>\n",
       "      <td>32,496</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>27,870</td>\n",
       "      <td>31,790</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>27,283</td>\n",
       "      <td>-</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>24,603</td>\n",
       "      <td>-</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>3.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>22,287</td>\n",
       "      <td>26,503</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RANK                      STATE GSDP(18-19)- at current prices  \\\n",
       "0     1                Maharashtra                      2,632,792   \n",
       "1     2                 Tamil Nadu                      1,630,208   \n",
       "2     3              Uttar Pradesh                      1,584,764   \n",
       "3     4                    Gujarat                      1,502,899   \n",
       "4     5                  Karnataka                      1,493,127   \n",
       "5     6                West Bengal                      1,089,898   \n",
       "6     7                  Rajasthan                        942,586   \n",
       "7     8             Andhra Pradesh                        862,957   \n",
       "8     9                  Telangana                        861,031   \n",
       "9    10             Madhya Pradesh                        809,592   \n",
       "10   11                     Kerala                        781,653   \n",
       "11   12                      Delhi                        774,870   \n",
       "12   13                    Haryana                        734,163   \n",
       "13   14                      Bihar                        530,363   \n",
       "14   15                     Punjab                        526,376   \n",
       "15   16                     Odisha                        487,805   \n",
       "16   17                      Assam                        315,881   \n",
       "17   18               Chhattisgarh                        304,063   \n",
       "18   19                  Jharkhand                        297,204   \n",
       "19   20                Uttarakhand                        245,895   \n",
       "20   21            Jammu & Kashmir                        155,956   \n",
       "21   22           Himachal Pradesh                        153,845   \n",
       "22   23                        Goa                         73,170   \n",
       "23   24                    Tripura                         49,845   \n",
       "24   25                 Chandigarh                         42,114   \n",
       "25   26                 Puducherry                         34,433   \n",
       "26   27                  Meghalaya                         33,481   \n",
       "27   28                     Sikkim                         28,723   \n",
       "28   29                    Manipur                         27,870   \n",
       "29   30                   Nagaland                         27,283   \n",
       "30   31          Arunachal Pradesh                         24,603   \n",
       "31   32                    Mizoram                         22,287   \n",
       "32   33  Andaman & Nicobar Islands                              -   \n",
       "\n",
       "   GSDP(19-20)- at current prices Share(18-19) GDP($ billion)  \n",
       "0                               -       13.94%        399.921  \n",
       "1                       1,845,853        8.63%        247.629  \n",
       "2                       1,687,818        8.39%        240.726  \n",
       "3                               -        7.96%        228.290  \n",
       "4                       1,631,977        7.91%        226.806  \n",
       "5                       1,253,832        5.77%        165.556  \n",
       "6                       1,020,989        4.99%        143.179  \n",
       "7                         972,782        4.57%        131.083  \n",
       "8                         969,604        4.56%        130.791  \n",
       "9                         906,672        4.29%        122.977  \n",
       "10                              -        4.14%        118.733  \n",
       "11                        856,112        4.10%        117.703  \n",
       "12                        831,610        3.89%        111.519  \n",
       "13                        611,804        2.81%         80.562  \n",
       "14                        574,760        2.79%         79.957  \n",
       "15                        521,275        2.58%         74.098  \n",
       "16                              -        1.67%         47.982  \n",
       "17                        329,180        1.61%         46.187  \n",
       "18                        328,598        1.57%         45.145  \n",
       "19                              -        1.30%         37.351  \n",
       "20                              -        0.83%         23.690  \n",
       "21                        165,472        0.81%         23.369  \n",
       "22                         80,449        0.39%         11.115  \n",
       "23                         55,984        0.26%          7.571  \n",
       "24                              -        0.22%          6.397  \n",
       "25                         38,253        0.18%          5.230  \n",
       "26                         36,572        0.18%          5.086  \n",
       "27                         32,496        0.15%          4.363  \n",
       "28                         31,790        0.15%          4.233  \n",
       "29                              -        0.14%          4.144  \n",
       "30                              -        0.13%          3.737  \n",
       "31                         26,503        0.12%          3.385  \n",
       "32                              -            -              -  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe for different attributes\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'RANK':rank,'STATE':state,'GSDP(18-19)- at current prices':GSDP_18_19 ,'GSDP(19-20)- at current prices':GSDP_19_20,\n",
    "                   \"Share(18-19)\":share_18_19,\"GDP($ billion)\":GDP })\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb10d029",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">4. Scrape the details of trending repositories on Github.com. Url = https://github.com/         \n",
    "You have to find the following details:                 \n",
    "A) Repository title                    \n",
    "B) Repository description                  \n",
    "C) Contributors count                      \n",
    "D) Language used                                     \n",
    "Note: - From the home page you have to click on the trending option from Explore menu through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "bb313523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Chrome WebDriver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\nirma\\Downloads\\chromedriver-win64\\chromedriver-win64\\chromedriver.exe\")\n",
    "driver.get(\"https://github.com/\")\n",
    "driver.maximize_window()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "99db48b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click on explore button\n",
    "Explore = driver.find_element(By.XPATH,\"/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/button\")\n",
    "Explore.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "39772f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select trending option\n",
    "trending = driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/div/div[3]/ul/li[2]/a')\n",
    "trending.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "d98ca6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty list\n",
    "repo_urls = []  \n",
    "rep_title = []\n",
    "Description =[]\n",
    "Contributors=[]\n",
    "Language=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "64f68d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping urls for each repository\n",
    "repository = driver.find_elements(By.XPATH,'//a[@class=\"Link\"]')\n",
    "for i in repository[0:24]:\n",
    "    repo_urls.append(i.get_attribute(\"href\"))\n",
    "\n",
    "    \n",
    "#Scraping data from every repository page\n",
    "for i in repo_urls:\n",
    "    driver.get(i)\n",
    "    time.sleep(3)\n",
    "    \n",
    "    #Scraping title-                           \n",
    "    try:\n",
    "        title = driver.find_element(By.XPATH,'//strong[@class=\"mr-2 flex-self-stretch\"]')\n",
    "        rep_title.append(title.text)\n",
    "    except NoSuchElementException:\n",
    "        rep_title.append('-')  \n",
    "    \n",
    "    #Scraping description-\n",
    "    try:\n",
    "        desc = driver.find_element(By.XPATH,'//p[@class=\"f4 my-3\"]')\n",
    "        Description.append(desc.text)\n",
    "    except NoSuchElementException:\n",
    "        Description.append('-')\n",
    "        \n",
    "        \n",
    "    #Scraping contributors count-\n",
    "    try:\n",
    "        cont_tags = driver.find_element(By.XPATH,\"//*[contains(text(),'Contributors')]\")\n",
    "        Contributors.append(cont_tags.text.replace('Contributors',''))\n",
    "    except NoSuchElementException:\n",
    "        Contributors.append('-')\n",
    "        \n",
    "        \n",
    "    #Scraping Languages-\n",
    "    try:\n",
    "        cont_tags = driver.find_element(By.XPATH,'//span[@class=\"color-fg-default text-bold mr-1\"]')\n",
    "        Language.append(cont_tags.text)\n",
    "    except NoSuchElementException:\n",
    "        Language.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "29021e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository title</th>\n",
       "      <th>Repository description</th>\n",
       "      <th>Contributors count</th>\n",
       "      <th>Language used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>system-design-101</td>\n",
       "      <td>Explain complex systems using visuals and simp...</td>\n",
       "      <td>\\n5</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XAgent</td>\n",
       "      <td>An Autonomous LLM Agent for Complex Task Solving</td>\n",
       "      <td>\\n10</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ionic-framework</td>\n",
       "      <td>A powerful cross-platform UI toolkit for build...</td>\n",
       "      <td>\\n468</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MemGPT</td>\n",
       "      <td>Teaching LLMs memory management for unbounded ...</td>\n",
       "      <td>\\n10</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>thorium</td>\n",
       "      <td>Chromium fork named after radioactive element ...</td>\n",
       "      <td>\\n9</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Free-Certifications</td>\n",
       "      <td>A curated list of free courses &amp; certifications.</td>\n",
       "      <td>\\n53</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>unleashed-firmware</td>\n",
       "      <td>Flipper Zero Unleashed Firmware</td>\n",
       "      <td>\\n292</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RemoveAdblockThing</td>\n",
       "      <td>Removes The \"Ad blocker are not allowed on You...</td>\n",
       "      <td></td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>refine</td>\n",
       "      <td>Build your React-based CRUD applications, with...</td>\n",
       "      <td></td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PokemonRedExperiments</td>\n",
       "      <td>Playing Pokemon Red with Reinforcement Learning</td>\n",
       "      <td>\\n4</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Thorium-Win</td>\n",
       "      <td>Chromium fork for Windows named after radioact...</td>\n",
       "      <td>-</td>\n",
       "      <td>Batchfile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>programming-language-research</td>\n",
       "      <td>Programming Language Research, Applied PLT &amp; C...</td>\n",
       "      <td>\\n4</td>\n",
       "      <td>Clojure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>imersao15</td>\n",
       "      <td>-</td>\n",
       "      <td>\\n3</td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>langchain</td>\n",
       "      <td>⚡ Building applications with LLMs through comp...</td>\n",
       "      <td>\\n1,712</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>azure-search-openai-demo</td>\n",
       "      <td>A sample app for the Retrieval-Augmented Gener...</td>\n",
       "      <td>\\n49</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>fullstackweek-store</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>azure-sdk-for-java</td>\n",
       "      <td>This repository is for active development of t...</td>\n",
       "      <td></td>\n",
       "      <td>Java</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>trufflehog</td>\n",
       "      <td>Find and verify credentials</td>\n",
       "      <td></td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>kong</td>\n",
       "      <td>🦍 The Cloud-Native API Gateway</td>\n",
       "      <td>\\n352</td>\n",
       "      <td>Lua</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>next-auth</td>\n",
       "      <td>Authentication for the Web.</td>\n",
       "      <td>\\n595</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>create-t3-app</td>\n",
       "      <td>The best way to start a full-stack, typesafe N...</td>\n",
       "      <td></td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>GaussianSplats3D</td>\n",
       "      <td>Three.js-based implementation of the 3D Gaussi...</td>\n",
       "      <td>-</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>GOAD</td>\n",
       "      <td>game of active directory</td>\n",
       "      <td>\\n15</td>\n",
       "      <td>PowerShell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>workers-sdk</td>\n",
       "      <td>⛅️ Home to Wrangler, the CLI for Cloudflare Wo...</td>\n",
       "      <td>\\n126</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Repository title  \\\n",
       "0               system-design-101   \n",
       "1                          XAgent   \n",
       "2                 ionic-framework   \n",
       "3                          MemGPT   \n",
       "4                         thorium   \n",
       "5             Free-Certifications   \n",
       "6              unleashed-firmware   \n",
       "7              RemoveAdblockThing   \n",
       "8                          refine   \n",
       "9           PokemonRedExperiments   \n",
       "10                    Thorium-Win   \n",
       "11  programming-language-research   \n",
       "12                      imersao15   \n",
       "13                      langchain   \n",
       "14       azure-search-openai-demo   \n",
       "15            fullstackweek-store   \n",
       "16             azure-sdk-for-java   \n",
       "17                     trufflehog   \n",
       "18                           kong   \n",
       "19                      next-auth   \n",
       "20                  create-t3-app   \n",
       "21               GaussianSplats3D   \n",
       "22                           GOAD   \n",
       "23                    workers-sdk   \n",
       "\n",
       "                               Repository description Contributors count  \\\n",
       "0   Explain complex systems using visuals and simp...                \\n5   \n",
       "1    An Autonomous LLM Agent for Complex Task Solving               \\n10   \n",
       "2   A powerful cross-platform UI toolkit for build...              \\n468   \n",
       "3   Teaching LLMs memory management for unbounded ...               \\n10   \n",
       "4   Chromium fork named after radioactive element ...                \\n9   \n",
       "5    A curated list of free courses & certifications.               \\n53   \n",
       "6                     Flipper Zero Unleashed Firmware              \\n292   \n",
       "7   Removes The \"Ad blocker are not allowed on You...                      \n",
       "8   Build your React-based CRUD applications, with...                      \n",
       "9     Playing Pokemon Red with Reinforcement Learning                \\n4   \n",
       "10  Chromium fork for Windows named after radioact...                  -   \n",
       "11  Programming Language Research, Applied PLT & C...                \\n4   \n",
       "12                                                  -                \\n3   \n",
       "13  ⚡ Building applications with LLMs through comp...            \\n1,712   \n",
       "14  A sample app for the Retrieval-Augmented Gener...               \\n49   \n",
       "15                                                  -                  -   \n",
       "16  This repository is for active development of t...                      \n",
       "17                        Find and verify credentials                      \n",
       "18                     🦍 The Cloud-Native API Gateway              \\n352   \n",
       "19                        Authentication for the Web.              \\n595   \n",
       "20  The best way to start a full-stack, typesafe N...                      \n",
       "21  Three.js-based implementation of the 3D Gaussi...                  -   \n",
       "22                           game of active directory               \\n15   \n",
       "23  ⛅️ Home to Wrangler, the CLI for Cloudflare Wo...              \\n126   \n",
       "\n",
       "       Language used  \n",
       "0                  -  \n",
       "1         TypeScript  \n",
       "2         TypeScript  \n",
       "3             Python  \n",
       "4                C++  \n",
       "5                  -  \n",
       "6                  C  \n",
       "7         JavaScript  \n",
       "8         TypeScript  \n",
       "9   Jupyter Notebook  \n",
       "10         Batchfile  \n",
       "11           Clojure  \n",
       "12                Go  \n",
       "13            Python  \n",
       "14            Python  \n",
       "15        TypeScript  \n",
       "16              Java  \n",
       "17                Go  \n",
       "18               Lua  \n",
       "19        TypeScript  \n",
       "20        TypeScript  \n",
       "21        JavaScript  \n",
       "22        PowerShell  \n",
       "23        TypeScript  "
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'Repository title':rep_title,'Repository description':Description,\n",
    "                   'Contributors count':Contributors,'Language used':Language})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9845b171",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">5. Scrape the details of top 100 songs on billiboard.com. Url = https:/www.billboard.com/        \n",
    "You have to find the following details:                            \n",
    "A) Song name                          \n",
    "B) Artist name                  \n",
    "C) Last week rank                    \n",
    "D) Peak rank              \n",
    "E) Weeks on board               \n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "66b06ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Chrome WebDriver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\nirma\\Downloads\\chromedriver-win64\\chromedriver-win64\\chromedriver.exe\")\n",
    "driver.get(\"https://www.billboard.com/\")\n",
    "driver.maximize_window()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "178dc001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click on chart\n",
    "charts = driver.find_element(By.XPATH,\"/html/body/div[3]/header/div/div[2]/div/div/div[2]/div[2]/div/div/nav/ul/li[1]/a\")\n",
    "charts.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "bb056c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click on billboard_100songs\n",
    "billboard_100songs = driver.find_element(By.XPATH,'/html/body/div[3]/main/div[2]/div[1]/div[1]/div/div/div[3]/a')\n",
    "billboard_100songs.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5274873d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the 100 songs with details\n",
    "\n",
    "#scraping the song name \n",
    "song_name=[]\n",
    "try:\n",
    "    name = driver.find_elements(By.XPATH,\"//div[@class='o-chart-results-list-row-container']//ul/li//h3\")\n",
    "    for i in name:\n",
    "        song_name.append(i.text)\n",
    "except NoSuchElementException:  #handling no such element exception\n",
    "    song_name.append(\"-\")\n",
    "except StaleElementReferenceException: #handling Stale element exception\n",
    "    song_name.append(\"-\")\n",
    "time.sleep(2) \n",
    "\n",
    "\n",
    "#scraping the artist\n",
    "artist =[]\n",
    "try:\n",
    "    art=driver.find_elements(By.XPATH,\"//li[@class='lrv-u-width-100p']//ul//li[1]//span\")\n",
    "    for i in art:\n",
    "        artist.append(i.text)\n",
    "except NoSuchElementException: #handling no such element exception\n",
    "    artist.append(\"-\")\n",
    "except StaleElementReferenceException: #handling Stale element exception\n",
    "    artist.append(\"-\")\n",
    "time.sleep(2) \n",
    "\n",
    "#scraping the Last week rank\n",
    "last_week_rank =[]\n",
    "try:\n",
    "    rank=driver.find_elements(By.XPATH,\"//li[@class='o-chart-results-list__item // a-chart-color u-width-72 u-width-55@mobile-max u-width-55@tablet-only lrv-u-flex lrv-u-flex-shrink-0 lrv-u-align-items-center lrv-u-justify-content-center lrv-u-border-b-1 u-border-b-0@mobile-max lrv-u-border-color-grey-light u-background-color-white-064@mobile-max u-hidden@mobile-max'][1]//span[1]\")\n",
    "    for i in rank:\n",
    "        last_week_rank.append(i.text)\n",
    "except NoSuchElementException: #handling no such element exception\n",
    "    last_week_rank.append(\"-\")\n",
    "except StaleElementReferenceException: #handling Stale element exception\n",
    "    last_week_rank.append(\"-\")\n",
    "time.sleep(2) \n",
    "\n",
    "#scraping the peak rank\n",
    "peak_rank =[]\n",
    "try:\n",
    "    p_rank=driver.find_elements(By.XPATH,\"//li[@class='o-chart-results-list__item // a-chart-bg-color a-chart-color u-width-72 u-width-55@mobile-max u-width-55@tablet-only lrv-u-flex lrv-u-flex-shrink-0 lrv-u-align-items-center lrv-u-justify-content-center lrv-u-background-color-grey-lightest lrv-u-border-b-1 u-border-b-0@mobile-max lrv-u-border-color-grey-light u-hidden@mobile-max'][2]\")\n",
    "    for i in p_rank:\n",
    "        peak_rank.append(i.text)\n",
    "except NoSuchElementException: #handling no such element exception\n",
    "    peak_rank.append(\"-\")\n",
    "except StaleElementReferenceException: #handling Stale element exception\n",
    "    peak_rank.append(\"-\")\n",
    "time.sleep(2)\n",
    "\n",
    "#scraping the Weeks on board\n",
    "Weeks_board=[]\n",
    "try:\n",
    "    board=driver.find_elements(By.XPATH,\"//li[@class='o-chart-results-list__item // a-chart-color u-width-72 u-width-55@mobile-max u-width-55@tablet-only lrv-u-flex lrv-u-flex-shrink-0 lrv-u-align-items-center lrv-u-justify-content-center lrv-u-border-b-1 u-border-b-0@mobile-max lrv-u-border-color-grey-light u-background-color-white-064@mobile-max u-hidden@mobile-max'][2]//span[1]\")\n",
    "    for i in rank:\n",
    "        Weeks_board.append(i.text)\n",
    "except NoSuchElementException: #handling no such element exception\n",
    "    Weeks_board.append(\"-\")\n",
    "except StaleElementReferenceException: #handling Stale element exception\n",
    "    Weeks_board.append(\"-\")\n",
    "time.sleep(2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "01369015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100 100 100\n"
     ]
    }
   ],
   "source": [
    "#print the length of each column  \n",
    "print(len(song_name),len(artist),len(last_week_rank),len(Weeks_board),len(peak_rank))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4df7457f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SONG NAME</th>\n",
       "      <th>ARTIST</th>\n",
       "      <th>LAST WEEK RANK</th>\n",
       "      <th>PEAK RANK</th>\n",
       "      <th>WEEK BOARD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>First Person Shooter</td>\n",
       "      <td>Drake Featuring J. Cole</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IDGAF</td>\n",
       "      <td>Drake Featuring Yeat</td>\n",
       "      <td>-</td>\n",
       "      <td>2</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Virginia Beach</td>\n",
       "      <td>Drake</td>\n",
       "      <td>-</td>\n",
       "      <td>3</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Paint The Town Red</td>\n",
       "      <td>Doja Cat</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Calling For You</td>\n",
       "      <td>Drake Featuring 21 Savage</td>\n",
       "      <td>-</td>\n",
       "      <td>5</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>God Gave Me A Girl</td>\n",
       "      <td>Russell Dickerson</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Y Lloro</td>\n",
       "      <td>Junior H</td>\n",
       "      <td>-</td>\n",
       "      <td>97</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Telekinesis</td>\n",
       "      <td>Travis Scott Featuring SZA &amp; Future</td>\n",
       "      <td>72</td>\n",
       "      <td>26</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Seven</td>\n",
       "      <td>Jung Kook Featuring Latto</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Stars Like Confetti</td>\n",
       "      <td>Dustin Lynch</td>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               SONG NAME                               ARTIST LAST WEEK RANK  \\\n",
       "0   First Person Shooter              Drake Featuring J. Cole              -   \n",
       "1                  IDGAF                 Drake Featuring Yeat              -   \n",
       "2         Virginia Beach                                Drake              -   \n",
       "3     Paint The Town Red                             Doja Cat              1   \n",
       "4        Calling For You            Drake Featuring 21 Savage              -   \n",
       "..                   ...                                  ...            ...   \n",
       "95    God Gave Me A Girl                    Russell Dickerson             90   \n",
       "96               Y Lloro                             Junior H              -   \n",
       "97           Telekinesis  Travis Scott Featuring SZA & Future             72   \n",
       "98                 Seven            Jung Kook Featuring Latto             57   \n",
       "99   Stars Like Confetti                         Dustin Lynch             89   \n",
       "\n",
       "   PEAK RANK WEEK BOARD  \n",
       "0          1          -  \n",
       "1          2          -  \n",
       "2          3          -  \n",
       "3          1          1  \n",
       "4          5          -  \n",
       "..       ...        ...  \n",
       "95        90         90  \n",
       "96        97          -  \n",
       "97        26         72  \n",
       "98         1         57  \n",
       "99        89         89  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "billboard = pd.DataFrame({'SONG NAME':song_name,'ARTIST':artist,'LAST WEEK RANK':last_week_rank ,'PEAK RANK':peak_rank,\"WEEK BOARD\":Weeks_board})\n",
    "billboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0aeabd7",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">6. Scrape the details of Highest selling novels.             \n",
    "A) Book name                     \n",
    "B) Author name                     \n",
    "C) Volumes sold               \n",
    "D) Publisher                 \n",
    "E) Genre                      \n",
    "Url - https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "757c4884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Chrome WebDriver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\nirma\\Downloads\\chromedriver-win64\\chromedriver-win64\\chromedriver.exe\")\n",
    "driver.get(\"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\")\n",
    "driver.maximize_window()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1d46ee60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the Book names\n",
    "name =[]\n",
    "try:\n",
    "    names=driver.find_elements(By.XPATH,\"//table[@class='in-article sortable']/tbody/tr/td[2]\")\n",
    "    for i in names:\n",
    "        name.append(i.text)\n",
    "except NoSuchElementException: #handling no such element exception\n",
    "    name.append('No details available')\n",
    "except StaleElementReferenceException: #handling Stale element exception\n",
    "    name.append('No details available')\n",
    "    time.sleep(2) \n",
    "\n",
    "#scraping the Author names\n",
    "author_name =[]\n",
    "try:\n",
    "    author=driver.find_elements(By.XPATH,\"//table[@class='in-article sortable']/tbody/tr/td[3]\")\n",
    "    for i in author:\n",
    "        author_name.append(i.text)\n",
    "except NoSuchElementException: #handling no such element exception\n",
    "    author_name.append('No details available')\n",
    "except StaleElementReferenceException: #handling Stale element exception\n",
    "    author_name.append('No details available')\n",
    "    time.sleep(2) \n",
    "\n",
    "#scraping the Volumes sold\n",
    "volume_sold= []\n",
    "try:\n",
    "    sold=driver.find_elements(By.XPATH,\"//table[@class='in-article sortable']/tbody/tr/td[4]\")\n",
    "    for i in  sold:\n",
    "        volume_sold.append(i.text)\n",
    "except NoSuchElementException: #handling no such element exception\n",
    "    volume_sold.append('No details available')\n",
    "except StaleElementReferenceException: #handling Stale element exception\n",
    "    volume_sold.append('No details available')\n",
    "    time.sleep(2) \n",
    "\n",
    "#scraping the publisher\n",
    "publisher= []\n",
    "try:\n",
    "    pub=driver.find_elements(By.XPATH,\"//table[@class='in-article sortable']/tbody/tr/td[5]\")\n",
    "    for i in  pub:\n",
    "        publisher.append(i.text)\n",
    "except NoSuchElementException: #handling no such element exception\n",
    "    publisher.append('No details available')\n",
    "except StaleElementReferenceException: #handling Stale element exception\n",
    "    publisher.append('No details available')\n",
    "    time.sleep(2) \n",
    "\n",
    "#scraping the genre\n",
    "Genre = []\n",
    "try:\n",
    "    genre=driver.find_elements(By.XPATH,\"//table[@class='in-article sortable']/tbody/tr/td[6]\")\n",
    "    for i in  genre:\n",
    "        Genre.append(i.text)\n",
    "except NoSuchElementException: #handling no such element exception\n",
    "    Genre.append('No details available')\n",
    "except StaleElementReferenceException: #handling Stale element exception\n",
    "    Genre.append('No details available')\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1262a317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BOOK NAME</th>\n",
       "      <th>AUTHOR NAME</th>\n",
       "      <th>VOLUME SOLD</th>\n",
       "      <th>PUBLISHER</th>\n",
       "      <th>GENRE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            BOOK NAME       AUTHOR NAME  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   VOLUME SOLD        PUBLISHER                        GENRE  \n",
       "0    5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1    4,475,152       Bloomsbury           Children's Fiction  \n",
       "2    4,200,654       Bloomsbury           Children's Fiction  \n",
       "3    4,179,479       Bloomsbury           Children's Fiction  \n",
       "4    3,758,936     Random House              Romance & Sagas  \n",
       "..         ...              ...                          ...  \n",
       "95     807,311     Random House   General & Literary Fiction  \n",
       "96     794,201          Penguin        Food & Drink: General  \n",
       "97     792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98     791,507            Orion           Biography: General  \n",
       "99     791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "book = pd.DataFrame({'BOOK NAME':name,'AUTHOR NAME':author_name,'VOLUME SOLD':volume_sold ,'PUBLISHER':publisher,\"GENRE\":Genre})\n",
    "book"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f383fc3",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">7. Scrape the details most watched tv series of all time from imdb.com.              \n",
    "Url = https://www.imdb.com/list/ls095964455/ You have to find the following details:                      \n",
    "A) Name                 \n",
    "B) Year span                \n",
    "C) Genre               \n",
    "D) Run time                \n",
    "E) Ratings             \n",
    "F) Votes          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1fc43bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Chrome WebDriver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\nirma\\Downloads\\chromedriver-win64\\chromedriver-win64\\chromedriver.exe\")\n",
    "driver.get(\"https://www.imdb.com/list/ls095964455/\")\n",
    "driver.maximize_window()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b74f02b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the names\n",
    "name =[]\n",
    "try:\n",
    "    names=driver.find_elements(By.XPATH,\"//h3[@class='lister-item-header']/a\")\n",
    "    for i in names[:100]:\n",
    "        name.append(i.text)\n",
    "except NoSuchElementException: #handling no such element exception\n",
    "    name.append('No details available')\n",
    "except StaleElementReferenceException: #handling Stale element exception\n",
    "    name.append('No details available')\n",
    "    time.sleep(2) \n",
    "\n",
    "#scraping the year\n",
    "Year_span = []\n",
    "try:\n",
    "    Year=driver.find_elements(By.XPATH,\"//h3[@class='lister-item-header']/span[2]\")\n",
    "    for i in  Year[:100]:\n",
    "        Year_span.append(i.text)\n",
    "except NoSuchElementException: #handling no such element exception\n",
    "    Year_span.append('No details available')\n",
    "except StaleElementReferenceException: #handling Stale element exception\n",
    "    Year_span.append('No details available')\n",
    "    time.sleep(2) \n",
    "\n",
    "#scraping the genre\n",
    "Genre = []\n",
    "try:\n",
    "    genre=driver.find_elements(By.XPATH,\"//span[@class='genre']\")\n",
    "    for i in  genre[:100]:\n",
    "        Genre.append(i.text)\n",
    "except NoSuchElementException: #handling no such element exception\n",
    "    Genre.append('No details available')\n",
    "except StaleElementReferenceException: #handling Stale element exception\n",
    "    Genre.append('No details available')\n",
    "    time.sleep(2) \n",
    "\n",
    "#scraping the run time\n",
    "run_time = []\n",
    "try:\n",
    "    time=driver.find_elements(By.XPATH,\"//span[@class='runtime']\")\n",
    "    for i in time[:100]:\n",
    "        run_time.append(i.text)\n",
    "except NoSuchElementException: #handling no such element exception\n",
    "    run_time.append('No details available')\n",
    "except StaleElementReferenceException: #handling Stale element exception\n",
    "    run_time.append('No details available')\n",
    "    time.sleep(2) \n",
    "    \n",
    "#scraping the rating\n",
    "rating = []\n",
    "try:\n",
    "    rate=driver.find_elements(By.XPATH,\"//span[@class='runtime']\")\n",
    "    for i in rate[:100]:\n",
    "        rating.append(i.text)\n",
    "except NoSuchElementException: #handling no such element exception\n",
    "    rating.append('No details available')\n",
    "except StaleElementReferenceException: #handling Stale element exception\n",
    "    rating.append('No details available')\n",
    "    time.sleep(2) \n",
    "    \n",
    "#scraping the votes\n",
    "votes= []\n",
    "try:\n",
    "    Vote=driver.find_elements(By.XPATH,\"//p[@class='text-muted text-small'][3]/span[2]\")\n",
    "    for i in Vote[:100]:\n",
    "        votes.append(i.text)\n",
    "except NoSuchElementException: #handling no such element exception\n",
    "    votes.append('No details available')\n",
    "except StaleElementReferenceException: #handling Stale element exception\n",
    "    votes.append('No details available')\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "92104641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>GENRE</th>\n",
       "      <th>RUN TIME</th>\n",
       "      <th>RATING</th>\n",
       "      <th>VOTES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>57 min</td>\n",
       "      <td>2,213,339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016–2025)</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>51 min</td>\n",
       "      <td>1,283,152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>44 min</td>\n",
       "      <td>1,050,220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>60 min</td>\n",
       "      <td>308,611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>43 min</td>\n",
       "      <td>267,545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>42 min</td>\n",
       "      <td>52,952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>50 min</td>\n",
       "      <td>65,025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005– )</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>42 min</td>\n",
       "      <td>211,898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>45 min</td>\n",
       "      <td>44,104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>572 min</td>\n",
       "      <td>269,950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              NAME         YEAR                     GENRE  \\\n",
       "0                  Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things  (2016–2025)    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010–2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013–2017)                     Drama   \n",
       "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds     (2005– )     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015–2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "   RUN TIME   RATING      VOTES  \n",
       "0    57 min   57 min  2,213,339  \n",
       "1    51 min   51 min  1,283,152  \n",
       "2    44 min   44 min  1,050,220  \n",
       "3    60 min   60 min    308,611  \n",
       "4    43 min   43 min    267,545  \n",
       "..      ...      ...        ...  \n",
       "95   42 min   42 min     52,952  \n",
       "96   50 min   50 min     65,025  \n",
       "97   42 min   42 min    211,898  \n",
       "98   45 min   45 min     44,104  \n",
       "99  572 min  572 min    269,950  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "cinema = pd.DataFrame({'NAME':name,'YEAR':Year_span,'GENRE':Genre ,'RUN TIME':run_time,\"RATING\":rating,\"VOTES\":votes})\n",
    "cinema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054d6edd",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">8. Details of Datasets from UCI machine learning repositories.          \n",
    "Url = https://archive.ics.uci.edu/ You have to find the following details:                    \n",
    "A) Dataset name                 \n",
    "B) Data type             \n",
    "C) Task                 \n",
    "D) Attribute type                \n",
    "E) No of instances                \n",
    "F) No of attribute G) Year                               \n",
    "Note: - from the home page you have to go to the Show All Dataset page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "2da0404f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Chrome WebDriver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\nirma\\Downloads\\chromedriver-win64\\chromedriver-win64\\chromedriver.exe\")\n",
    "driver.get(\"https://archive.ics.uci.edu/\")\n",
    "driver.maximize_window()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "f5d7603d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click on viewdataset link\n",
    "view_dataset=driver.find_element(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[1]/div/div/div/a[1]')\n",
    "view_dataset.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "0f2bd4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click on expand all\n",
    "expand=driver.find_element(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[2]/div[1]/div/label[2]/div[2]/span[2]')\n",
    "expand.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "b123481b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the dataset names\n",
    "dataset_name =[]\n",
    "try:\n",
    "    names=driver.find_elements(By.XPATH,'//a[@class=\"link-hover link text-xl font-semibold\"]')\n",
    "    for i in names:\n",
    "        dataset_name.append(i.text)\n",
    "except NoSuchElementException: #handling no such element exception\n",
    "    dataset_name.append('No details available')\n",
    "except StaleElementReferenceException: #handling Stale element exception\n",
    "    dataset_name.append('No details available')\n",
    "    time.sleep(2)        \n",
    "    \n",
    "#scraping the Data type\n",
    "data_type =[]\n",
    "try:\n",
    "    data=driver.find_elements(By.XPATH,'//div[@class=\"my-2 hidden gap-4 md:grid grid-cols-12\"]/div[2]/span')\n",
    "    for i in data:\n",
    "        data_type.append(i.text)\n",
    "except NoSuchElementException: #handling no such element exception\n",
    "    data_type.append('No details available')\n",
    "except StaleElementReferenceException: #handling Stale element exception\n",
    "    data_type.append('No details available')\n",
    "    time.sleep(2)\n",
    "\n",
    "#scraping the task\n",
    "task=[]\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//div[@class=\"my-2 hidden gap-4 md:grid grid-cols-12\"]/div[1]/span'):\n",
    "        task.append(i.text)\n",
    "except NoSuchElementException: #handling no such element exception\n",
    "    task.append('No details available')\n",
    "except StaleElementReferenceException: #handling Stale element exception\n",
    "    taskappend('No details available')\n",
    "    time.sleep(2)\n",
    "        \n",
    "#scraping the Attribute type\n",
    "Attribute=[]\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//table[@class=\"col-span-full my-2 table sm:col-start-2\"]/tbody/tr/td[2]'):\n",
    "        Attribute.append(i.text)\n",
    "except NoSuchElementException: #handling no such element exception\n",
    "    Attribute.append('No details available')\n",
    "except StaleElementReferenceException: #handling Stale element exception\n",
    "    Attribute.append('No details available')\n",
    "    time.sleep(2)   \n",
    "        \n",
    "#scraping the No of instances\n",
    "instances=[]\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//div[@class=\"my-2 hidden gap-4 md:grid grid-cols-12\"]/div[3]/span'):\n",
    "        instances.append(i.text)\n",
    "except NoSuchElementException: #handling no such element exception\n",
    "    instances.append('No details available')\n",
    "except StaleElementReferenceException: #handling Stale element exception\n",
    "    instances.append('No details available')\n",
    "    time.sleep(2)\n",
    "        \n",
    "#scraping the  No of attribute\n",
    "attribute=[]\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//div[@class=\"my-2 hidden gap-4 md:grid grid-cols-12\"]/div[4]/span'):\n",
    "        attribute.append(i.text)\n",
    "except NoSuchElementException: #handling no such element exception\n",
    "    attribute.append('No details available')\n",
    "except StaleElementReferenceException: #handling Stale element exception\n",
    "    attribute.append('No details available')\n",
    "    time.sleep(2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "9d8d7e05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset name</th>\n",
       "      <th>Data type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute type</th>\n",
       "      <th>No of instances</th>\n",
       "      <th>No of attribute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Heart Disease</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>303 Instances</td>\n",
       "      <td>13 Features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48.84K Instances</td>\n",
       "      <td>14 Features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wine</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>178 Instances</td>\n",
       "      <td>13 Features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Breast Cancer Wisconsin (Diagnostic)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>569 Instances</td>\n",
       "      <td>30 Features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Diabetes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td></td>\n",
       "      <td>20 Features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dry Bean Dataset</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>13.61K Instances</td>\n",
       "      <td>16 Features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Car Evaluation</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>1.73K Instances</td>\n",
       "      <td>6 Features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Rice (Cammeo and Osmancik)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>3.81K Instances</td>\n",
       "      <td>8 Features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mushroom</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>8.12K Instances</td>\n",
       "      <td>22 Features</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Dataset name     Data type            Task  \\\n",
       "1                         Heart Disease  Multivariate  Classification   \n",
       "2                                 Adult  Multivariate  Classification   \n",
       "3                                  Wine       Tabular  Classification   \n",
       "4  Breast Cancer Wisconsin (Diagnostic)  Multivariate  Classification   \n",
       "5                              Diabetes                                 \n",
       "6                      Dry Bean Dataset  Multivariate  Classification   \n",
       "7                        Car Evaluation  Multivariate  Classification   \n",
       "8            Rice (Cammeo and Osmancik)  Multivariate  Classification   \n",
       "9                              Mushroom  Multivariate  Classification   \n",
       "\n",
       "               Attribute type   No of instances No of attribute  \n",
       "1  Categorical, Integer, Real     303 Instances     13 Features  \n",
       "2        Categorical, Integer  48.84K Instances     14 Features  \n",
       "3               Integer, Real     178 Instances     13 Features  \n",
       "4                        Real     569 Instances     30 Features  \n",
       "5        Categorical, Integer                       20 Features  \n",
       "6               Integer, Real  13.61K Instances     16 Features  \n",
       "7                 Categorical   1.73K Instances      6 Features  \n",
       "8                        Real   3.81K Instances      8 Features  \n",
       "9                 Categorical   8.12K Instances     22 Features  "
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'Dataset name':dataset_name,'Data type':data_type ,'Task':task ,'Attribute type':Attribute,\n",
    "                   \"No of instances\":instances,\"No of attribute\":attribute})\n",
    "df.drop([0], inplace = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6744ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
